import cv2
import numpy as np
import mediapipe as mp
import pyttsx3
import time

# Initialize text-to-speech engine
engine = pyttsx3.init()
engine.setProperty('rate', 150)  # Speech speed
engine.setProperty('volume', 1.0)  # Max volume

# Load Mediapipe Face Mesh
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)

# Eye and face turn detection thresholds
EYE_CLOSED_THRESHOLD = 0.25  # Threshold for drowsiness detection
DROWSINESS_TIME_THRESHOLD = 2  # Time in seconds

HEAD_TURN_THRESHOLD = 0.08  # Adjust this value for sensitivity (higher = less sensitive)
HEAD_TURN_TIME_THRESHOLD = 2  # Time in seconds for head turn alert

# Track eye closure and head movement time
eye_closed_start = None
head_turn_start = None

# Define landmark indices for eyes and head pose estimation
LEFT_EYE = [362, 385, 387, 263, 373, 380]
RIGHT_EYE = [33, 160, 158, 133, 153, 144]
NOSE_TIP = 1
LEFT_CHEEK = 234
RIGHT_CHEEK = 454

# Function to generate a voice alert
def voice_alert(message):
    print("ALERT:", message)
    engine.say(message)
    engine.runAndWait()

# Function to calculate Eye Aspect Ratio (EAR)
def eye_aspect_ratio(eye):
    """ Calculate eye aspect ratio (EAR) to detect closed eyes """
    vertical_1 = np.linalg.norm(np.array(eye[1]) - np.array(eye[5]))
    vertical_2 = np.linalg.norm(np.array(eye[2]) - np.array(eye[4]))
    horizontal = np.linalg.norm(np.array(eye[0]) - np.array(eye[3]))
    return (vertical_1 + vertical_2) / (2.0 * horizontal)

# Function to get landmark coordinates
def get_landmark_coords(face_landmarks, indices, frame_width, frame_height):
    return [(int(face_landmarks.landmark[i].x * frame_width),
             int(face_landmarks.landmark[i].y * frame_height)) for i in indices]

# Open webcam
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("Error: Unable to open webcam.")
    exit()

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Flip the frame horizontally for natural viewing
    frame = cv2.flip(frame, 1)

    # Convert frame to RGB (Mediapipe requires RGB)
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb_frame)

    frame_height, frame_width, _ = frame.shape

    if results.multi_face_landmarks:
        for face_landmarks in results.multi_face_landmarks:
            # Get eye landmarks
            left_eye = get_landmark_coords(face_landmarks, LEFT_EYE, frame_width, frame_height)
            right_eye = get_landmark_coords(face_landmarks, RIGHT_EYE, frame_width, frame_height)

            # Get head pose landmarks
            nose_x = face_landmarks.landmark[NOSE_TIP].x
            left_cheek_x = face_landmarks.landmark[LEFT_CHEEK].x
            right_cheek_x = face_landmarks.landmark[RIGHT_CHEEK].x

            # Calculate EAR
            left_ear = eye_aspect_ratio(left_eye)
            right_ear = eye_aspect_ratio(right_eye)
            avg_ear = (left_ear + right_ear) / 2.0  # Average of both eyes

            print(f"EAR: {avg_ear:.3f}")  # Debugging EAR values

            # Draw eye landmarks
            for (x, y) in left_eye + right_eye:
                cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)

            # Check if eyes are closed (Drowsiness Detection)
            if avg_ear < EYE_CLOSED_THRESHOLD:
                if eye_closed_start is None:
                    eye_closed_start = time.time()
                elif time.time() - eye_closed_start > DROWSINESS_TIME_THRESHOLD:
                    voice_alert("Warning! You are feeling drowsy.Slow down And Stop the Vehicle Immediately.")
                    cv2.putText(frame, "DROWSY!", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)
            else:
                eye_closed_start = None  # Reset if eyes are open

            # Head Pose Detection (Checking if looking sideways)
            head_direction = nose_x - (left_cheek_x + right_cheek_x) / 2

            if abs(head_direction) > HEAD_TURN_THRESHOLD:
                if head_turn_start is None:
                    head_turn_start = time.time()
                elif time.time() - head_turn_start > HEAD_TURN_TIME_THRESHOLD:
                    voice_alert("Please look straight at the road")
                    cv2.putText(frame, "LOOK STRAIGHT!", (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 3)
            else:
                head_turn_start = None  # Reset if looking straight

    # Display the webcam feed
    cv2.imshow("Driver Monitoring System", frame)

    # Fix for OpenCV crash on macOS (M1/M2)
    key = cv2.waitKey(10)
    if key & 0xFF == ord('q'):
        break

# Release resources
cap.release()
cv2.destroyAllWindows()
